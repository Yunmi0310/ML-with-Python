{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A LOOK AT KERAS DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras has built-in datasets\n",
    "import keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load mnist dataset\n",
    "data_mnist = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the shape of this nd second : Vector of size : 60000\n",
    "print(data_mnist[1][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mnist[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the type of the dataset is a tuple (we can guess that there is training and test dataset) \n",
    "print(type(data_mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the length of the dataset tuple is 2 even more sure that there is training and test dataset) \n",
    "print(len(data_mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's access the first element an check its type\n",
    "print(type(data_mnist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a 2 tuple -> chances  are that it contains data and the label\n",
    "print(len(data_mnist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### X_train : first element of the first element in the parent 2-tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the size of the first element : we red 60 k observations\n",
    "print(len(data_mnist[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the type of the first element : it is a n-dimensional array\n",
    "print(type(data_mnist[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the shape of this nd array : tensor of order 3 : 60000x28x28\n",
    "print(data_mnist[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Y_train : second element of the first elment in the parent 2-tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the size of the second element : we red 60 k observations\n",
    "print(len(data_mnist[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the type of the first second : it is a n-dimensional array\n",
    "print(type(data_mnist[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the shape of this nd second : Vector of size : 60000\n",
    "print(data_mnist[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### X_test : first element of the second element in the parent 2-tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the size of the first element : we red 10 k observations\n",
    "print(len(data_mnist[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the type of the first element : it is a n-dimensional array\n",
    "print(type(data_mnist[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the shape of this nd second : tensor of order 3 : 10000x28x28\n",
    "print(data_mnist[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Y_test : second element of the second element in the parent 2-tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the size of the first element : we red 10 k observations\n",
    "print(len(data_mnist[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the type of the first element : it is a n-dimensional array\n",
    "print(type(data_mnist[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUILD CLASSES (DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset():\n",
    "    def __init__(self,data):\n",
    "        # the class propperty X_train is populated  with the elements of data\n",
    "        # as explained above\n",
    "        self.X_train = data[0][0]\n",
    "        self.Y_train = data[0][1]\n",
    "        self.X_test = data[1][0]\n",
    "        self.Y_test = data[1][1]\n",
    "    \n",
    "    def get_stats(self):\n",
    "        # this function displays the number of observations\n",
    "        my_str = \"there are {0} training observations, {1} test observations\".format(len(self.X_train), len(self.X_test))\n",
    "        print(my_str)\n",
    "        \n",
    "    def check_dataset_health(self):\n",
    "        # checkup function which checks that X and Y have the same number of observations\n",
    "        assert self.X_train.shape[0] == self.Y_train.shape[0]\n",
    "        assert self.X_test.shape[0] == self.Y_test.shape[0]\n",
    "        print(\"dataset is ok\")\n",
    "        \n",
    "    def preview(self, image_index =0):\n",
    "        # display the observation @ a chosen index\n",
    "        label_at_index = self.Y_train[image_index]\n",
    "        plt.title(\"image index nÂ° {0} and the associated label is {1}\".format(image_index, label_at_index))\n",
    "        plt.imshow(self.X_train[image_index], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate new Dataset class\n",
    "new_mnist_dataset = myDataset(data_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mnist_dataset.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mnist_dataset.Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the new instance health\n",
    "new_mnist_dataset.check_dataset_health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stats of the new dataset \n",
    "new_mnist_dataset.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the visual of an image at index =k \n",
    "new_mnist_dataset.preview(image_index =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXERCICE 1:\n",
    "- Try to recreate the same apporach for FashionMNIST dataset\n",
    "-  Try to add additional info in the stats : image size,  class distribution (how many observations par class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten,Dense,Dropout\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class My_predictive_model():\n",
    "    \n",
    "    def mod_definition(self):\n",
    "        # define inputs size\n",
    "        img_width, img_height = 48, 48\n",
    "        \n",
    "        # model without output (transfert learning)\n",
    "        model = VGG16(weights = None, include_top=False, input_shape = (img_width, img_height, 1))\n",
    "\n",
    "        # freeze all layers\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Adding custom Layers \n",
    "        x = model.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(10, activation=\"softmax\")(x)\n",
    "        \n",
    "        #final model using the VGG16 structure to which we added a block\n",
    "        model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "        # compile the model ( define the loss, the optimizer and the monitored metrics)\n",
    "        adadelta = optimizers.Adadelta(lr=0.001)\n",
    "        model_final.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n",
    "\n",
    "        return(model_final)\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        #when the model is initialized it calls the function (mod_definition)\n",
    "        self.model = self.mod_definition()\n",
    "        \n",
    "        \n",
    "    def train_model(self,x_train,y_train):\n",
    "        # when the model is trained : in this case it fits x_train, y_train - in memory  (not done in practice)\n",
    "        # specify 20 epochs and the batch size here : 10\n",
    "        # this could be changed or parameterized\n",
    "        \n",
    "        self.model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=10)\n",
    "        \n",
    "        \n",
    "    def predict_img(self, img):\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def predict_path(self, path):\n",
    "        img = image.load_img(img_path, target_size=(48, 48))\n",
    "        return self.model.predict_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "pred_model = My_predictive_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output =[]\n",
    "# we will resize the images to the target size\n",
    "for el in tqdm.tqdm(new_mnist_dataset.X_train):\n",
    "    list_output.append(cv2.resize(el, (48,48)))\n",
    "\n",
    "# we will output the \"stacked images as an array\" \n",
    "list_output = np.array(list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation des labels  to be converted in 1-hot encoding\n",
    "categorical = keras.utils.to_categorical(new_mnist_dataset.Y_train,num_classes=10)\n",
    "# preparation des images en input to have 4 dimensions ( requirement for conv2D networks)\n",
    "expanded = np.expand_dims(list_output, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAINING (prediction on 1 image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "pred_model.train_model(expanded, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TESTING (prediction on 1 image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use a given image\n",
    "img_path = '/Users/assansanogo/Downloads/elephant.jpeg'\n",
    "#let's load the image\n",
    "img = image.load_img(img_path, target_size=(48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 10 predictions (the sum = 1)\n",
    "print(pred_model.predict_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the  final answer (to : \"what number is it like ?\"\")\n",
    "label_pred = np.argmax(pred_model.predict_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset():\n",
    "    def __init__(dataset_name, file_path_link):\n",
    "        self.ds_name = dataset_name\n",
    "        self.link = file_path_link\n",
    "        self.path_unzip = os.getcwd()\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "        self.X_test = None\n",
    "        self.Y_test = None\n",
    "        self.csv_file_path = \"\"\n",
    "        \n",
    "    def download():\n",
    "        # here is an url of your choice \n",
    "        url = self.link\n",
    "        # here is a destination path\n",
    "        file_zip_path = os.path.join(self.path_unzip,self.ds_name)\n",
    "        os.makedirs(file_zip_path, exist_ok = True)\n",
    "\n",
    "        # we want to check that the url is valid before downloading\n",
    "        with urlrequest.urlopen(url) as response:\n",
    "            resp_status = response.status\n",
    "        \n",
    "            # if the error code is 200 we process to downloading else we don't\n",
    "            if resp_status ==200 and not os.path.exists(file_zip_path):\n",
    "                # download the file if the response code is 200\n",
    "                file_,resp = urlrequest.urlretrieve(url)\n",
    "\n",
    "            elif os.path.exists(file_jpg_path):\n",
    "                print(\"Please check the destination folder, the image already exist\")\n",
    "            else:\n",
    "                print(\"Please check the link, the download link is not downloadable or does not exist\")\n",
    "    \n",
    "    def unzip_file():\n",
    "        with zipfile.ZipFile(file_zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(self.path_unzip)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your own !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
